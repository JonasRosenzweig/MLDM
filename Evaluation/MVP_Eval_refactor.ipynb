{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model, Tokenizer and LabelEncoder loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "THRESHOLD = 0.51\n",
    "SAMPLE_AMOUNT = 100\n",
    "RANDOM_STATE = 7\n",
    "TARGETS = ['Name', 'Description', 'Category', 'Price', 'Amount', 'EAN']\n",
    "\n",
    "model = keras.models.load_model(r'C:\\Users\\mail\\PycharmProjects\\MLDM\\Main\\Models\\organized\\6_class_MVP_v2.h5')\n",
    "tokenizer = pickle.load(open(r'C:\\Users\\mail\\PycharmProjects\\MLDM\\Main\\Models\\organized\\6_class_MVP_v2.pkl', 'rb'))\n",
    "le = LabelEncoder()\n",
    "print('Model, Tokenizer and LabelEncoder loaded.')\n",
    "\n",
    "def predictClass(text, tok, model):\n",
    "    text_pad = sequence.pad_sequences(tok.texts_to_sequences([text]), maxlen=300)\n",
    "    predict_x = model.predict(text_pad)\n",
    "    predict_class = np.argmax(predict_x, axis=1)\n",
    "    score = le.inverse_transform(predict_class)\n",
    "    prediction = score[0]\n",
    "    return prediction\n",
    "\n",
    "manual_map_Bisgaard = {0: 'EAN', 1: 'Unknown', 2: 'Description', 3: 'Description', 4: 'Unknown', 5: 'Description', 6: 'Unknown', 7: 'Amount',\n",
    "             8: 'Unknown', 9: 'Price', 10: 'Price', 11: 'Category', 12: 'Description', 13: 'Unknown', 14: 'Unknown', 15: 'Description',\n",
    "            16: 'Description', 17: 'Unknown', 18: 'Unknown', 19: 'Unknown', 20: 'Unknown', 21: 'Unknown', 22: 'Unknown', 23: 'Unknown',\n",
    "            24: 'Unknown', 25: 'Unknown'}\n",
    "manual_map_A_dataset = {0: 'Unknown', 1: 'Unknown', 2: 'Name', 3: 'Category', 4: 'Price', 5: 'EAN', 6: 'Unknown', 7: 'Amount', 8: 'Name',\n",
    "                       9: 'Unknown', 10: 'Unknown', 11: 'Unknown', 12: 'Unknown', 13: 'Unknown', 14: 'Unknown', 15: 'Unknown',16: 'Unknown',\n",
    "                       17: 'Unknown', 18: 'Description' }\n",
    "manual_map_A_Discount_bigbuy_da = {0: 'Unknown', 1: 'Category', 2: 'Name', 3: 'Description', 4: 'Description',\n",
    "                                   5: 'Amount'}\n",
    "manual_map_A_Discount_bigbuy_en = {0: 'Unknown', 1: 'Category', 2: 'Name', 3: 'Description', 4: 'Description',\n",
    "                                   5: 'Amount'}\n",
    "manual_map_A_Discount_Compressed1 = {0: 'Unknown', 1: 'Name', 2: 'Description', 3: 'EAN', 4: 'Category',\n",
    "                                     5: 'Category'}\n",
    "manual_map_A_Discount_Compressed2 = {0: 'Unknown', 1: 'Name', 2: 'Description', 3: 'EAN', 4:\n",
    "    'Category'}\n",
    "manual_map_A_Discount_presta_product_2399_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'EAN',\n",
    "                                                5: 'Description', 6: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2403_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Description',\n",
    "                                                5: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2507_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price', 5:\n",
    "    'EAN', 6: 'Description', 7: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2507_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price',\n",
    "                                                5: 'EAN', 6: 'Description', 7: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2570_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price',\n",
    "                                                5: 'EAN'}\n",
    "manual_map_A_Discount_presta_product_2570_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price',\n",
    "                                                5: 'EAN'}\n",
    "manual_map_A_Discount_presta_product_2662_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Unknown',\n",
    "                                                5: 'EAN', 6: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2662_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Unknown',\n",
    "                                                5: 'EAN', 6: 'Description', 7: 'Desription'}\n",
    "manual_map_A_Discount_presta_product_2678_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Unknown',\n",
    "                                                5: 'EAN', 6: 'Description'}\n",
    "manual_map_A_Discount_presta_product_2678_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Unknown',\n",
    "                                                5: 'EAN', 6: 'Description', 7: 'Description'}\n",
    "manual_map_A_Discount_presta_product_3046_da = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price',\n",
    "                                                5: 'Unknown', 6: 'EAN', 7: 'Description', 8: 'Description'}\n",
    "manual_map_A_Discount_presta_product_3046_en = {0: 'Unknown', 1: 'Name', 2: 'Price', 3: 'Price', 4: 'Price',\n",
    "                                                5: 'Unknown', 6: 'EAN', 7: 'Description', 8: 'Description'}\n",
    "manual_map_Scand = {0: 'Unknown', 1: 'Name', 2: 'Unknown', 3: 'EAN', 4: 'Amount', 5: 'Amount', 6: 'Amount',\n",
    "                    7: 'Unknown', 8: 'Unknown',\n",
    "             9: 'Price', 10: 'Price', 11: 'Price', 12: 'Price', 13: 'Unknown'}\n",
    "manual_map_items = {0: 'Unknown', 1: 'EAN', 2:'Name', 3: 'Unknown', 4: 'Price', 5: 'Amount', 6: 'Amount',\n",
    "                    7: 'Unknown', 8: 'Unknown', 9: 'Unknown',\n",
    "                   10: 'Unknown', 11: 'Unknown', 12: 'Unknown' }\n",
    "manual_map_Joha = {0: 'Unknown', 1: 'Unknown', 2: 'Unknown', 3: 'Category', 4: 'Unknown', 5: 'EAN', 6: 'Amount',\n",
    "                   7: 'Unknown', 8: 'Price', 9: 'Unknown',\n",
    "                  10: 'Unknown', 11: 'Unknown', 12: 'Unknown', 13: 'Unknown', 14: 'Unknown', 15: 'Description',\n",
    "                   16: 'Unknown' }\n",
    "manual_map_Modern_classic_upstart = {0: 'Amount', 1: 'Unknown', 2: 'Name', 3: 'EAN', 4: 'EAN', 5: 'Amount',\n",
    "                                     6: 'Price', 7: 'Price', 8: 'Price', 9: 'Price'}\n",
    "manual_map_PIF = {0: 'Unknown', 1: 'Name', 2: 'EAN', 3: 'Unknown', 4: 'Unknown', 5: 'Unknown', 6: 'Unknown',\n",
    "                  7: 'Unknown',  8: 'Unknown'}\n",
    "manual_map_prisliste ={0: 'Unknown', 1: 'Description', 2: 'Unknown', 3: 'Unknown', 4: 'Unknown', 5: 'Amount',\n",
    "                       6: 'Unknown', 7: 'Unknown', 8: 'Unknown', 9: 'Price', 10: 'Unknown', 11: 'Price',\n",
    "                       12: 'Price', 13: 'Unknown', 14:\n",
    "                       'Unknown', 15: 'Unknown', 16: 'Unknown', 17: 'EAN', 18: 'Unknown', 19: 'Unknown',\n",
    "                       20: 'Unknown', 21:\n",
    "                       'Unknown', 22: 'Unknown', 23: 'Unknown', 24: 'Unknown', 25: 'Unknown', 26: 'Unknown',\n",
    "                       27: 'Unknown', 28: 'Unknown'}\n",
    "manual_map_VAREFIL = {0: 'Unknown', 1: 'EAN', 2: 'Name', 3: 'Name', 4: 'Category',  5: 'Price', 6: 'Unknown',\n",
    "                      7: 'Unknown', 8: 'Unknown'}\n",
    "manual_maps = [manual_map_A_dataset, manual_map_A_Discount_bigbuy_da, manual_map_A_Discount_bigbuy_en,\n",
    "               manual_map_A_Discount_Compressed1, manual_map_A_Discount_Compressed2, manual_map_A_Discount_presta_product_2399_da,\n",
    "               manual_map_A_Discount_presta_product_2403_en, manual_map_A_Discount_presta_product_2507_da,\n",
    "               manual_map_A_Discount_presta_product_2507_en, manual_map_A_Discount_presta_product_2570_da,\n",
    "               manual_map_A_Discount_presta_product_2570_en, manual_map_A_Discount_presta_product_2662_da,\n",
    "               manual_map_A_Discount_presta_product_2662_en, manual_map_A_Discount_presta_product_2678_da,\n",
    "               manual_map_A_Discount_presta_product_2678_en, manual_map_A_Discount_presta_product_3046_da,\n",
    "               manual_map_A_Discount_presta_product_3046_en, manual_map_Bisgaard, manual_map_Scand, manual_map_items,\n",
    "              manual_map_Joha, manual_map_Modern_classic_upstart, manual_map_PIF, manual_map_prisliste, manual_map_VAREFIL]\n",
    "\n",
    "unknowns = []\n",
    "for l in range(len(manual_maps)):\n",
    "    unknowns.append(Counter(manual_maps[l].values())['Unknown'])\n",
    "\n",
    "PATH = r'C:\\Users\\mail\\Downloads\\data\\Eval Datasets'\n",
    "list_files = listdir(PATH)\n",
    "k = 0\n",
    "eval_list = []\n",
    "percent_list = []\n",
    "percent_list_known = []\n",
    "\n",
    "def evaluate(df):\n",
    "    if len(df.index) >= SAMPLE_AMOUNT:\n",
    "        try:\n",
    "            df = df.sample(SAMPLE_AMOUNT,\n",
    "                           random_state=RANDOM_STATE)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    df = df.reset_index(drop=True)\n",
    "    column_headers = list(df.columns)\n",
    "    # list of list of predictions including original column name\n",
    "    predictions_map = list(map(lambda item: [item], column_headers))\n",
    "\n",
    "    # list of list of predictions only - populate now then popped later\n",
    "    predictions_only = list(map(lambda item: [item], column_headers))\n",
    "\n",
    "    map_list = []\n",
    "    maps_object = []\n",
    "    Predictions = []\n",
    "    Certainty = []\n",
    "\n",
    "    for n in range(len(column_headers)):\n",
    "        print('----------Mapping column {num} of {len}----------'\n",
    "              .format(num=n+1, len=len(column_headers)))\n",
    "        df_select = df[column_headers[n]]\n",
    "        # sequence padding and tokenization of data requires string type\n",
    "        df_select = df_select.astype(str)\n",
    "        multiple_predictions = []\n",
    "        multiple_certainties = []\n",
    "        for m in range(len(df_select)):\n",
    "            class_predictions = []\n",
    "            targets = TARGETS\n",
    "            # fitting targets for label encoder\n",
    "            targets = le.fit_transform(targets)\n",
    "            data = df_select[m]\n",
    "            predicted_class = predictClass(data, tokenizer, model)\n",
    "            predictions_map[n].append(predicted_class)\n",
    "            predictions_only[n].append(predicted_class)\n",
    "            print('Data: {data}, Class Prediction: {prediction}'\n",
    "                  .format(data=data, prediction=predicted_class))\n",
    "\n",
    "        predictions_only[n].pop(0)\n",
    "        column_predictions = (predictions_only[n])\n",
    "        column_predictions_series = pd.Series(column_predictions)\n",
    "        column_predictions_count = column_predictions_series.value_counts()\n",
    "        print('map list:', predictions_map)\n",
    "        print('predictions only:', predictions_only)\n",
    "        print('column predictions:', column_predictions)\n",
    "        print('column predictions series:', column_predictions_series)\n",
    "        print('column predictions count:', column_predictions_count)\n",
    "        print('majority class:', column_predictions_count.index[0])\n",
    "        print('number of predictions:', column_predictions_count.iloc[0])\n",
    "        print('________________________')\n",
    "\n",
    "        if column_predictions_count.iloc[0] > len(df_select) * THRESHOLD:\n",
    "            print(column_predictions_count.index[0], 'is the Majority Predicted Class.')\n",
    "            print('The majority class is: {pred}; {num_pred} of {len} predictions.'\n",
    "                  '\\n Original Class: {origin}'\n",
    "                  .format(pred=column_predictions_count.index[0],\n",
    "                          num_pred=column_predictions_count.iloc[0],\n",
    "                          len=len(df_select),\n",
    "                          origin=column_headers[n]))\n",
    "            Predictions.append(column_predictions_count.index[0])\n",
    "            Certainty.append(100)\n",
    "\n",
    "        else:\n",
    "            print('There is no Majority Predicted Class above the threshold.'\n",
    "                  '\\n Original Class: {origin}'\n",
    "                  .format(origin=column_headers[n]))\n",
    "            for i in range(len(column_predictions_count)):\n",
    "                print('Predicted class {i}: {pred}; {num_pred} of {len} predictions.'\n",
    "                      .format(i=i+1,\n",
    "                              pred=column_predictions_count.index[i],\n",
    "                              num_pred=column_predictions_count.iloc[i],\n",
    "                              len=len(df_select)))\n",
    "                multiple_predictions.append(column_predictions_count.index[i])\n",
    "                multiple_certainties.append(column_predictions_count.iloc[i] / len(df_select) * 100)\n",
    "            Predictions.append(multiple_predictions)\n",
    "            Certainty.append(multiple_certainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Mapping column 1 of 19----------\n",
      "Data: 235F6X, Class Prediction: EAN\n",
      "Data: 2384TB, Class Prediction: EAN\n",
      "Data: 238EB5, Class Prediction: EAN\n",
      "Data: AJ6TU2, Class Prediction: EAN\n",
      "Data: 234DW8, Class Prediction: EAN\n",
      "Data: 2394EG, Class Prediction: EAN\n",
      "Data: 235PC7, Class Prediction: EAN\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-3fd1c9ec5ab8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mdataset_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../..\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPATH\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset_filename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror_bad_lines\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'c'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'UTF-8'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlow_memory\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-22-550c864a902f>\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m    144\u001B[0m             \u001B[0mtargets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_select\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 146\u001B[1;33m             \u001B[0mpredicted_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredictClass\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    147\u001B[0m             \u001B[0mpredictions_map\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredicted_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    148\u001B[0m             \u001B[0mpredictions_only\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredicted_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-22-550c864a902f>\u001B[0m in \u001B[0;36mpredictClass\u001B[1;34m(text, tok, model)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredictClass\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtok\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0mtext_pad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msequence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad_sequences\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtok\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtexts_to_sequences\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxlen\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m300\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m     \u001B[0mpredict_x\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext_pad\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m     \u001B[0mpredict_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredict_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m     \u001B[0mscore\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredict_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1645\u001B[0m       \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_predict_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1646\u001B[0m     \u001B[0mall_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure_up_to\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconcat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1647\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtf_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy_or_python_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_outputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1648\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1649\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mreset_metrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001B[0m in \u001B[0;36mto_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    512\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m  \u001B[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    513\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 514\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_to_single_numpy_or_python_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001B[0m in \u001B[0;36m_to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    508\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_to_single_numpy_or_python_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    509\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 510\u001B[1;33m       \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    511\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m  \u001B[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1069\u001B[0m     \"\"\"\n\u001B[0;32m   1070\u001B[0m     \u001B[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1071\u001B[1;33m     \u001B[0mmaybe_arr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1072\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaybe_arr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1073\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1035\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1036\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1037\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1038\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1039\u001B[0m       \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dataset_filename = os.listdir(PATH)[0]\n",
    "dataset_path = os.path.join(\"../..\", PATH, dataset_filename)\n",
    "df = pd.read_csv(dataset_path, error_bad_lines=False, engine='c', encoding='UTF-8', low_memory=False, dtype=str)\n",
    "evaluate(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}