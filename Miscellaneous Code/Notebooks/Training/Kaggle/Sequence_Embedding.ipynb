{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide a TPU Name to connect to.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9c18ffb7f1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# detect and init the TPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mtpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m# instantiate a distribution strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mtpu_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(tpu, zone, project)\u001b[0m\n\u001b[0;32m    107\u001b[0m       \u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0mfound\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mresolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTPUClusterResolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mremote\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect_to_cluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'local'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m       \u001b[1;31m# Default Cloud environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       self._cloud_tpu_client = client.Client(\n\u001b[0m\u001b[0;32m    202\u001b[0m           \u001b[0mtpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m           \u001b[0mzone\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\tpu\\client\\client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_as_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, f1_score, auc\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# random seed for reproducibility\n",
    "random.seed(7)\n",
    "\n",
    "# for TPU debugging\n",
    "#ctpu up --tpu-size=[TPU_VERSION] --tf-version=[TF VERSION]\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "df = pd.read_csv(\"../input/6-class-mvp/6_class_MVP_dataset_2D.csv\", names=[\"text\", \"target\"],\n",
    "                 encoding=\"UTF-8\", skiprows=1, low_memory=False, index_col=False)\n",
    "print(\"done loading\")\n",
    "\n",
    "# not sure if needed\n",
    "df=df.sample(frac=1)\n",
    "df=df.astype(str)\n",
    "\n",
    "# seaborn coutplot to see class balance\n",
    "sns.coutplot(df.target)\n",
    "\n",
    "print(\"dataset size: {size} data points.\".format(size=df.size))\n",
    "print(\"index size:{size}\".format(size=df.index.size))\n",
    "num_classes=df.target.nunique()\n",
    "print('class count: {c}'.format(c=num_classes))\n",
    "\n",
    "inputs=df.text\n",
    "targets=df.target\n",
    "\n",
    "# label targets with label encoder\n",
    "le=LabelEncoder()\n",
    "targets-=le.fit_transform(targets)\n",
    "targets=targets.reshape(-1,1)\n",
    "\n",
    "# split training set from rest of data\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test_split(inputs, targets, test_size=0.2)\n",
    "\n",
    "# max words for input size\n",
    "max_words=1000\n",
    "\n",
    "# max length for sequence padding (can be reduced)\n",
    "max_len=300\n",
    "\n",
    "# tokenize inputs for word embedding\n",
    "tok=Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(train_inputs)\n",
    "\n",
    "# turn text to sequences for word embedding\n",
    "sequences=tok.texts_to_sequences(train_inputs)\n",
    "\n",
    "# pad sequences (add 0 at the end if len(sequences) < max_len)\n",
    "sequences_matrix=sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "# test sequences and padding\n",
    "test_sequences = tok.texts_to_sequences(test_inputs)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "\n",
    "# define Neural Network Sequential Keras model\n",
    "def RNN():\n",
    "    model = Sequential()\n",
    "    model.add(Input(name='inputs',shape=[max_len]))\n",
    "    model.add(Embedding(max_words,150,input_length=max_len))\n",
    "    model.add(LSTM(256, dropout=0.1, recurrent_dropout=0.1))\n",
    "    model.add(Dense(512,name='Dense1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(300,name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(300,name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense((num_classes),name='out_layer'))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "# plotting functions\n",
    "def plot(history, info_type='loss'):\n",
    "    plt.plot(history.history[info_type], label=[info_type])\n",
    "    try:\n",
    "        plt.plot(history.history['val_' + info_type], label=['val_' + info_type])\n",
    "    except Exception:\n",
    "        print(f'no val_{info_type}')\n",
    "    plt.title(info_type)\n",
    "    plt.legend()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    model = RNN()\n",
    "    model.summary()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=(tf.keras.optimizers.Adam(learning_rate=0.001)),metrics=['accuracy'])\n",
    "    history = model.fit(sequences_matrix,train_targets,batch_size=8000,epochs=250, validation_split=0.2,callbacks=[EarlyStopping(monitor='val_accuracy',min_delta=0.0005, patience=5)])\n",
    "    accr = model.evaluate(test_sequences_matrix,test_targets)\n",
    "    print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "    test_targets_list = list(test_targets)\n",
    "    predictions = model.predict_classes(test_sequences_matrix, verbose=1, batch_size=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes=df.target.unique()\n",
    "classes = list(classes)\n",
    "print(classes)\n",
    "print(classification_report(test_targets_list, predictions, target_names=classes))\n",
    "accuracy_score(test_targets_list, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_targets_list, predictions)\n",
    "plt.figure(figsize=(50, 50))\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('6_C_Sequence.h5')\n",
    "pickle.dump(tok, open('6_C_Sequence.pkl', \"wb\"), protocol=0)\n",
    "print('Model Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
