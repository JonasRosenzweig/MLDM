{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\mail\\pycharmprojects\\saleship\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gensim-4.1.2-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mail\\pycharmprojects\\saleship\\venv\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import gensim\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Activation\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 8000\n",
    "EPOCHS = 25\n",
    "random.seed(7)\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "df = pd.read_csv('../input/6-class-oversampled/6_class_MVP_dataset_2D.csv', names=['input','target'], encoding='ISO-8859-1', skiprows=1, low_memory=False, index_col=False)\n",
    "print('Dataset Size {size} rows.'.format(size=len(df.index)))\n",
    "\n",
    "sns.countplot(df.target)\n",
    "\n",
    "num_classes = df.target.nunique()\n",
    "\n",
    "inputs = df.input\n",
    "targets = df.target\n",
    "\n",
    "# word2vec\n",
    "docs = []\n",
    "for t in df.input:\n",
    "    docs.append(t.split())\n",
    "w2v_model = gensim.models.Word2Vec(vector_size=300, window=7, min_count=10, workers=8)\n",
    "w2v_model.build_vocab(docs)\n",
    "words = w2v_model.wv\n",
    "vocab_size = len(words)\n",
    "w2v_model.train(docs, total_examples=len(docs), epochs=32)\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.input)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# tokenize input\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(df.input), maxlen=300)\n",
    "\n",
    "# labelencoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df.target.tolist())\n",
    "\n",
    "y = encoder.transform(df.target.tolist())\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# embedding layer for NN\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=300, trainable=False)\n",
    "\n",
    "# callbacks\n",
    "callbacks = [EarlyStopping(monitor='accuracy', min_delta=0.0001, patience=2, restore_best_weights=True)]\n",
    "\n",
    "# merge inputs and targets\n",
    "inputs = x\n",
    "targets = y\n",
    "\n",
    "# K-Fold cross-validation\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# split data into test/train sets\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test_split(inputs, targets, test_size=0.2)\n",
    "\n",
    "\n",
    "# training loop\n",
    "with tpu_strategy.scope():\n",
    "    #for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense((num_classes)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=(tf.keras.optimizers.Adam(learning_rate=0.001)),metrics=['accuracy'])\n",
    "    #history = model.fit(inputs[train], targets[train], batch_size = BATCH_SIZE, epochs = EPOCHS, verbose = 1, callbacks=callbacks)\n",
    "    history = model.fit(train_inputs, train_targets, batch_size = BATCH_SIZE, epochs = EPOCHS, verbose = 1, callbacks=callbacks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accr = model.evaluate(test_inputs,test_targets)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(history, info_type='loss'):\n",
    "    plt.plot(history.history[info_type], label=[info_type])\n",
    "    try:\n",
    "        plt.plot(history.history['val_' + info_type], label=['val_' + info_type])\n",
    "    except Exception:\n",
    "        print(f'no val_{info_type}')\n",
    "    plt.title(info_type)\n",
    "    plt.legend()\n",
    "\n",
    "plot(history)\n",
    "plot(history, 'accuracy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    test_targets_list = list(test_targets)\n",
    "    predictions = model.predict_classes(test_inputs, verbose=1, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "classes=df.target.unique()\n",
    "classes = list(classes)\n",
    "print(classes)\n",
    "print(classification_report(test_targets_list, predictions, target_names=classes))\n",
    "accuracy_score(test_targets_list, predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)\n",
    "\n",
    "classes=df.target.unique()\n",
    "cnf_matrix = confusion_matrix(test_targets_list, predictions)\n",
    "plt.figure(figsize=(50, 50))\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, title=\"Confusion matrix\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save('6_C_Word.h5')\n",
    "pickle.dump(tokenizer, open('6_C_Word.pkl', \"wb\"), protocol=0)\n",
    "print('Model Saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}